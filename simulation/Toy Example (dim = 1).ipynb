{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duqiming2004/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Example (dim = 1)\n",
    "* $X \\sim \\mathcal{N}(0,1)$ r.v that we could simulate\n",
    "* $S:\\mathbb{R} \\to \\mathbb{R}$ score function / blackbox i.e. we could simulate $S(X)$, but we don't know the form of $S$. here we take $S(X) = |X| $\n",
    "* Goal : estimate $p = \\mathbb{P}(S(X)>q) < 10^{-6}$ ( q = 5 rare event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import autojit\n",
    "@autojit\n",
    "def S(X):\n",
    "    '''score function which is a black box'''\n",
    "    return np.abs(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### remark\n",
    "(cf. Sequential Monte Carlo for Rare Event Estimation(F.Cérou, P.Del Moral, T.Furon, A.Guyader)):\n",
    "http://www.lsta.lab.upmc.fr/modules/resources/download/labsta/Pages/Guyader/cdfg.pdf\n",
    "\n",
    "## Fixed-levels Algorithm:\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "N: the number of particles\n",
    "\n",
    "$\\{L_0,...,L_n\\}$: the sequence of levels, where $L_0 = -\\infty$\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "Draw an i.i.d. N-sample $(X_0^j)_{1\\leq j\\leq N}$ of law $\\mu$\n",
    "\n",
    "#### Iterations\n",
    "\n",
    "*for k = 0 to n-1:*\n",
    "\n",
    "Let $I_k  = \\{j : X_k^j \\in A_{k+1}\\}$ where $A_{k+1} = \\{x \\in \\mathbb{R}^d : S(x) > L_k\\}$\n",
    "\n",
    "Let $\\hat p_k = \\frac{\\#|T_k|}{N}$\n",
    "\n",
    "if $j \\in I_k$, let $\\tilde X_{k+1}^j = X_k^j$\n",
    "\n",
    "if $j \\notin I_k$, let $\\tilde X_{k+1}^j$ be a copy of $X_k^l$ where $l$ is chosen randomly in $I_k$ with uniform\n",
    "probabilities.\n",
    "\n",
    "\n",
    "\n",
    "############# *Question* ################\n",
    "\n",
    "\n",
    "The multinominal method of choosing $\\tilde X_{k+1}^j$ becomes expensive when the particle number increase. At the same time, there would be a problem when $I_k$ is empty, which would be possible when the level becomes large (i.e the $A_{k+1}$ is rare), a possible solution is to regenerate an $X_{new} \\sim \\mathcal{L}( X | S(X)>L_{k+1})$ with rejection sampling(this could ensure that the $I_k$ is not empty). However, this method end up with an analogue version of classic monte-carlo procedure.\n",
    "\n",
    "\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "We will use a trick to simplify the multinominal: we get new copie of $\\tilde X_{k+1}^j$ by doing the permutation to $I_k$, i.e. we will use a deterministic method.\n",
    "\n",
    "This procedure is far more effecient than the generation mentioned above. However, to ensure that $I_k$ is not empty for every level k, we should draw a big number of particles. \n",
    "########################################\n",
    "\n",
    "\n",
    "*for j from 1 to N:*\n",
    "\n",
    "Draw a new particle $\\hat X_{k+1}^j \\sim K(\\tilde X_{k+1}^j,\\cdot )$\n",
    "\n",
    "if $\\hat X_{k+1}^j \\in A_{k+1}$, let $X_{k+1}^j = \\hat X_{k+1}^j$, else let $X_{k+1}^j = \\tilde X_{k+1}^j$\n",
    "\n",
    "(that is to say, with the condition that $X \\in A_{k+1}$, we will only accept the transition in $A_{k+1}$ )\n",
    "\n",
    "#### Output\n",
    "\n",
    "Estimate the proba of the rare events by $\\hat p = \\prod_{k = 0}^{n - 1} \\hat p_k $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_0 =  0.5 \t n_0 = 13 \t r =  0.518901626194\n",
      "sequence of levels:  [       -inf  0.67448975  1.15034938  1.53412054  1.86273187  2.15387469\n",
      "  2.41755902  2.66006747  2.88563491  3.09726908  3.29719335  3.4871041\n",
      "  3.66832929  4.        ]\n",
      "num_lev:  14\n",
      "level interested, L =  4\n",
      "real value of p: 6.33424836662e-05\n",
      "theoric relative variance:  3.73190937117\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# sequence of levels\n",
    "\n",
    "q_test = 4\n",
    "\n",
    "p = (1-norm.cdf(q_test))*2\n",
    "\n",
    "###idealized situation\n",
    "p_0 = 0.5 #success rate\n",
    "n_0 = int(np.log(p)/np.log(p_0))\n",
    "r = p/(p_0**n_0)\n",
    "\n",
    "print \"p_0 = \", p_0, '\\t n_0 =',n_0,\"\\t r = \",r\n",
    "\n",
    "L = [-np.Inf]\n",
    "for k in range(1,n_0,1):\n",
    "    L = np.append(L, norm.ppf(1-p_0**k/2))\n",
    "L_ideal = np.append(L, q_test)\n",
    "num_lev = len(L_ideal)\n",
    "\n",
    "##var_relative\n",
    "sigma_theoric = np.sqrt(n_0*(1-p_0)/p_0 + (1-r)/r)\n",
    "print \"sequence of levels: \", L_ideal\n",
    "print \"num_lev: \",num_lev\n",
    "print \"level interested, L = \",q_test\n",
    "# real value of p\n",
    "print \"real value of p:\" ,p\n",
    "print \"theoric relative variance: \", sigma_theoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (1-norm.cdf(3.66832929))*2*r\n",
    "p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_tuning:  0.5\n",
      "levels:  [       -inf  0.67448975  1.15034938  1.53412054  1.86273187  2.15387469\n",
      "  2.41755902  2.66006747  2.88563491  3.09726908  3.29719335  3.4871041\n",
      "  3.66832929  4.        ]\n",
      "k =  0\n",
      "k =  1\n",
      "k =  2\n",
      "k =  3\n",
      "k =  4\n",
      "k =  5\n",
      "k =  6\n",
      "k =  7\n",
      "k =  8\n",
      "k =  9\n",
      "k =  10\n",
      "k =  11\n",
      "k =  12\n",
      "real value of p: 6.33424836662e-05\n",
      "estimation of p:  5.43891736941e-13\n",
      "relative variation:  99.9999991413\n",
      "N:  10000\n"
     ]
    }
   ],
   "source": [
    "#tuning parameter \n",
    "sigma_1 = 1\n",
    "#std_tuning = np.sqrt(sigma_1**2)/(1+sigma_1**2)\n",
    "std_tuning = np.float(sigma_1**2)/(1+sigma_1**2)\n",
    "c = np.sqrt(1+sigma_1**2)\n",
    "L = L_ideal\n",
    "\n",
    "\n",
    "print \"std_tuning: \",std_tuning\n",
    "print \"levels: \", L\n",
    "\n",
    "\n",
    "###Estimation of p\n",
    "\n",
    "N = 10000 # number of samples\n",
    "X= np.random.normal(0,1,N) \n",
    "p_hat = []\n",
    "\n",
    "for k in range(num_lev-1):\n",
    "    I = []\n",
    "    X_tilde = np.zeros(N)\n",
    "    print \"k = \", k \n",
    "    \n",
    "    \n",
    "###### construction of I_k \n",
    "    for j in range(N):\n",
    "        if S(X[j])>L[k+1]:\n",
    "            I = np.append(I,X[j])  \n",
    "    l = len(I)\n",
    "    p_hat = np.append(p_hat, l/np.float(N))\n",
    "    #print \"estimation of p_k\" ,p_hat[k]\n",
    "######\n",
    "\n",
    "    X_tilde[0:l] = I\n",
    "    I = np.random.permutation(I)\n",
    "    for i in range(l,N,1):\n",
    "        X_tilde[i] = I[i%l]\n",
    "    \n",
    "    for j in range(N):            \n",
    "        X_iter = np.random.normal(X_tilde[j]/c,std_tuning,1)\n",
    "        if S(X_iter)>L[k+1]:\n",
    "            X[j] = X_iter\n",
    "            \n",
    "    #print \"size of I_k: \", l\n",
    "    #print\"\\t\"\n",
    "    \n",
    "    \n",
    "\n",
    "var_rel = (p - np.prod(p_hat))/p*np.sqrt(N)\n",
    "print \"real value of p:\" ,p\n",
    "print \"estimation of p: \", np.prod(p_hat)\n",
    "print \"relative variation: \", var_rel\n",
    "print \"N: \",N\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remark\n",
    "(cf. Sequential Monte Carlo for Rare Event Estimation(F.Cérou, P.Del Moral, T.Furon, A.Guyader)):\n",
    "http://www.lsta.lab.upmc.fr/modules/resources/download/labsta/Pages/Guyader/cdfg.pdf\n",
    "\n",
    "\n",
    "## Adaptive Multilevel Splitting    \n",
    "\n",
    "#### parameter:\n",
    "\n",
    "$N$:  the number of particles\n",
    "\n",
    "$N_0$: the number of succeeding particles\n",
    "\n",
    "$p_0 = \\frac{N_0}{N}$ : the success rate\n",
    "\n",
    "$L$: the level we want to estimate\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "Draw an i.i.d. N-sample $(X_0^j)_{1\\leq j\\leq N}$ of law $\\mu$\n",
    "\n",
    "Compute the $\\hat L_1$, the $(1-p_0)$ quantile of $(S(X_0^j))_{1\\leq j \\leq N}$\n",
    "\n",
    "k = 1, index of level\n",
    "\n",
    "#### Iterations\n",
    "\n",
    "while $\\hat L_k < L$ do:\n",
    "\n",
    "Starting from an i.i.d. $p_0 N$-sample with law $\\mathcal{L}(X|S(X) > L_k)$,\n",
    "draw an i.i.d. $N$-sample $(X_k^j)_{1 \\leq j \\leq N}$ with the same law.\n",
    "\n",
    "################# *remark* ##################\n",
    "\n",
    "Here we use the same trick as in fixed-level splitting, i.e. to use a permutation to draw an an i.i.d. $(1-p_0)N$-sample $(X_k^j)_{1 \\leq j \\leq N}$ with the same law\n",
    "\n",
    "############################################\n",
    "\n",
    "Compute the $\\hat L_{k+1}$, the $(1-p_0)$ quantile of $(X_k^j)_{1 \\leq j \\leq N}$\n",
    "\n",
    "k = k + 1\n",
    "\n",
    "end while\n",
    "\n",
    "Calculate $N_L = \\#\\{j : S(X_{k-1}^j) \\geq L\\}$\n",
    "\n",
    "#### Output\n",
    "\n",
    "Estimate the probability of the rare event by $\\hat p = \\frac{N_L}{N}p_0^{k-1}$.\n",
    "\n",
    "#### remark\n",
    "\n",
    "* The adaptive version is biased \n",
    "\n",
    "$$bias \\sim O(\\frac1N)$$\n",
    "\n",
    "* The bias is non-negative, so the estimation is always a little bit overvalued\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real value of p: 5.73303143847e-07\n",
      "\t\n",
      "k =  1\n",
      "current level:  0.315792917037\n",
      "size of I_k:  37499\n",
      "\t\n",
      "k =  2\n",
      "current level:  0.574631450406\n",
      "size of I_k:  37499\n",
      "\t\n",
      "k =  3\n",
      "current level:  0.799863580496\n",
      "size of I_k:  37498\n",
      "\t\n",
      "k =  4\n",
      "current level:  1.0048239885\n",
      "size of I_k:  37498\n",
      "\t\n",
      "k =  5\n",
      "current level:  1.18350584757\n",
      "size of I_k:  37496\n",
      "\t\n",
      "k =  6\n",
      "current level:  1.34759376411\n",
      "size of I_k:  37498\n",
      "\t\n",
      "k =  7\n",
      "current level:  1.50429095836\n",
      "size of I_k:  37497\n",
      "\t\n",
      "k =  8\n",
      "current level:  1.64398678897\n",
      "size of I_k:  37486\n",
      "\t\n",
      "k =  9\n",
      "current level:  1.78520831734\n",
      "size of I_k:  37473\n",
      "\t\n",
      "k =  10\n",
      "current level:  1.91191289349\n",
      "size of I_k:  37472\n",
      "\t\n",
      "k =  11\n",
      "current level:  2.03953065117\n",
      "size of I_k:  37496\n",
      "\t\n",
      "k =  12\n",
      "current level:  2.15440841088\n",
      "size of I_k:  37476\n",
      "\t\n",
      "k =  13\n",
      "current level:  2.26519863098\n",
      "size of I_k:  37430\n",
      "\t\n",
      "k =  14\n",
      "current level:  2.37165248209\n",
      "size of I_k:  37426\n",
      "\t\n",
      "k =  15\n",
      "current level:  2.48618874771\n",
      "size of I_k:  37302\n",
      "\t\n",
      "k =  16\n",
      "current level:  2.5881412239\n",
      "size of I_k:  37462\n",
      "\t\n",
      "k =  17\n",
      "current level:  2.6824512775\n",
      "size of I_k:  37459\n",
      "\t\n",
      "k =  18\n",
      "current level:  2.77173232562\n",
      "size of I_k:  37351\n",
      "\t\n",
      "k =  19\n",
      "current level:  2.84726832195\n",
      "size of I_k:  37403\n",
      "\t\n",
      "k =  20\n",
      "current level:  2.93724500387\n",
      "size of I_k:  37234\n",
      "\t\n",
      "k =  21\n",
      "current level:  3.03684538505\n",
      "size of I_k:  37313\n",
      "\t\n",
      "k =  22\n",
      "current level:  3.10898840747\n",
      "size of I_k:  37012\n",
      "\t\n",
      "k =  23\n",
      "current level:  3.18398291815\n",
      "size of I_k:  36979\n",
      "\t\n",
      "k =  24\n",
      "current level:  3.284035754\n",
      "size of I_k:  37356\n",
      "\t\n",
      "k =  25\n",
      "current level:  3.37581111956\n",
      "size of I_k:  37293\n",
      "\t\n",
      "k =  26\n",
      "current level:  3.45164168818\n",
      "size of I_k:  37021\n",
      "\t\n",
      "k =  27\n",
      "current level:  3.52747890839\n",
      "size of I_k:  36358\n",
      "\t\n",
      "k =  28\n",
      "current level:  3.61020299018\n",
      "size of I_k:  32574\n",
      "\t\n",
      "k =  29\n",
      "current level:  3.68601300322\n",
      "size of I_k:  33282\n",
      "\t\n",
      "k =  30\n",
      "current level:  3.73584482578\n",
      "size of I_k:  37195\n",
      "\t\n",
      "k =  31\n",
      "current level:  3.9457230548\n",
      "size of I_k:  22625\n",
      "\t\n",
      "k =  32\n",
      "current level:  3.99773502784\n",
      "size of I_k:  29293\n",
      "final k =  33\n",
      "real value of p: 5.73303143847e-07\n",
      "estimation of p:  0.000100452425721\n",
      "relative variation:  38956.093301\n",
      "N:  50000\n"
     ]
    }
   ],
   "source": [
    "q_test = 5\n",
    "from scipy.stats import norm\n",
    "p = (1-norm.cdf(q_test))*2\n",
    "print \"real value of p:\" ,p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_0 = 0.75 # prescribed success rate\n",
    "N = 50000 #size of sample\n",
    "\n",
    "# calculate the empirical quantile of X\n",
    "#@autojit\n",
    "def L_empirical(X,alpha, N):\n",
    "    \n",
    "    #N = len(X)\n",
    "    #return np.percentile(np.sort(S(X)),(1-alpha)*100.,interpolation=\"lower\")\n",
    "    return np.sort(S(X))[np.int((1-alpha)*N)]\n",
    "\n",
    "###Estimation of p\n",
    "\n",
    "## To ensure that L_k != empty\n",
    "X = np.random.normal(0,1,N)\n",
    "while(np.sum((S(X)>q_test)) == 0):\n",
    "    X = np.random.normal(0,1,N)\n",
    "\n",
    "L = np.array([-np.Inf,L_empirical(X ,p_0 ,N )])\n",
    "k = 1\n",
    "\n",
    "while(L[k]<q_test):\n",
    "    print \"\\t\"\n",
    "    print \"k = \",k\n",
    "    print 'current level: ', L[k]\n",
    "    I = []\n",
    "    \n",
    " \n",
    "\n",
    "    for i in range(N):\n",
    "        if S(X[i])>L[k]:\n",
    "            I = np.append(I, X[i])\n",
    "    l = len(I)\n",
    "    print \"size of I_k: \", l\n",
    "       \n",
    "    X[0:l] = I\n",
    "    \n",
    "########## permutation trick to replace multinominal distribution\n",
    "    I = np.random.permutation(I)\n",
    "    for i in range(l,N,1):\n",
    "        X[i] = I[i%l]\n",
    "    \n",
    "            \n",
    "# rejection sampling = naive m.c.           \n",
    "#             while(S(X_tilde)<=L[k]):\n",
    "#                 X_tilde = np.random.normal(0,1,1)\n",
    "            \n",
    "\n",
    "#            X_new = np.append(X_new, X_tilde)         \n",
    "    \n",
    "    L = np.append(L, L_empirical(X,p_0 ,N))\n",
    "    k += 1\n",
    "\n",
    "print \"final k = \",k\n",
    "    \n",
    "N_L = np.sum((S(X)>q_test))\n",
    "p_hat = N_L/float(N)*p_0**(k-1)\n",
    "L_adapted = L[0:-1]\n",
    "L_adapted = np.append(L_adapted, q_test)\n",
    "\n",
    "print \"real value of p:\" ,p\n",
    "print \"estimation of p: \", p_hat\n",
    "print \"relative variation: \",np.abs((p - p_hat))/p*np.sqrt(N)\n",
    "print \"N: \",N\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_adapted = L[0:-1]\n",
    "L_adapted = np.append(L_adapted,q_test)\n",
    "print \"levels (adapted version): \", L_adapted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluctuation Analysis\n",
    "\n",
    "In this section we will do some analysis of the comportment of $\\frac{\\hat p - p}{p}$. In the idealized situation, by the thm of CTL, it converges to a normal law and we are interested in estimating the variance of this normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fixed_sim(N,sigma_1 = 1, L = L_ideal):\n",
    "    #tuning parameter \n",
    "    \n",
    "    std_tuning = np.sqrt(sigma_1**2)/(1+sigma_1**2)\n",
    "    c = np.sqrt(1+sigma_1**2)\n",
    "\n",
    "    #print \"std_tuning: \",std_tuning\n",
    "    #print \"levels: \", L\n",
    "\n",
    "\n",
    "    ###Estimation of p\n",
    "\n",
    "    X = np.random.normal(0,1,N)\n",
    "    while(np.sum((S(X)>q_test)) == 0):\n",
    "        X = np.random.normal(0,1,N)\n",
    "\n",
    " \n",
    "    p_hat = []\n",
    "    num_lev = len(L)\n",
    "    for k in range(num_lev-1):\n",
    "        I = []\n",
    "        X_tilde = np.zeros(N)\n",
    "        #print \"k = \", k \n",
    "\n",
    "\n",
    "    ###### construction of I_k \n",
    "        for j in range(N):\n",
    "            if S(X[j])>=L[k+1]:\n",
    "                I = np.append(I,X[j])  \n",
    "        l = len(I)\n",
    "        p_hat = np.append(p_hat, l/float(N))\n",
    "        #print \"estimation of p_k\" ,p_hat[k]\n",
    "    ######\n",
    "\n",
    "        X_tilde[0:l] = I\n",
    "        I = np.random.permutation(I)\n",
    "        for i in range(l,N,1):\n",
    "            X_tilde[i] = I[i%l]\n",
    "        #the shaker\n",
    "        for j in range(N):            \n",
    "            X_iter = np.random.normal(X_tilde[j]/c,std_tuning,1)\n",
    "            if S(X_iter)>L[k+1]:\n",
    "                X[j] = X_iter\n",
    "\n",
    "        #print \"size of I_k: \", l\n",
    "        #print\"\\t\"\n",
    "\n",
    "\n",
    "\n",
    "    var_rel = (p - np.prod(p_hat))/p*np.sqrt(N)\n",
    "    #print \"real value of p:\" ,p\n",
    "    #print \"estimation of p: \", np.prod(p_hat)\n",
    "    #print \"relative variation: \", var_rel\n",
    "    #print \"N: \",N\n",
    "    return np.prod(p_hat),var_rel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adapted_sim(N, q_test = 4, p_0 = 0.75):\n",
    "\n",
    "    p = (1-norm.cdf(q_test))*2\n",
    "#print \"real value of p:\" ,p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     # prescribed success rate\n",
    "\n",
    "\n",
    "    # calculate the empirical quantile of X\n",
    "    #@autojit\n",
    "\n",
    "    ###Estimation of p\n",
    "\n",
    "    ## To ensure that L_k != empty\n",
    "    X = np.random.normal(0,1,N)\n",
    "    while(np.sum((S(X)>q_test)) == 0):\n",
    "        X = np.random.normal(0,1,N)\n",
    "\n",
    "    L = np.array([-np.Inf,L_empirical(X, p_0, N)])\n",
    "    k = 1\n",
    "\n",
    "    while(L[k]<q_test):\n",
    "        #print \"\\t\"\n",
    "        #print \"k = \",k\n",
    "        #print 'current level: ', L[k]\n",
    "        I = []\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(N):\n",
    "            if S(X[i])>L[k]:\n",
    "                I = np.append(I, X[i])\n",
    "        l = len(I)\n",
    "        #print \"size of I_k: \", l\n",
    "\n",
    "        X[0:l] = I\n",
    "\n",
    "    ########## permutation trick to replace multinominal distribution\n",
    "        I = np.random.permutation(I)\n",
    "        for i in range(l,N,1):\n",
    "            X[i] = I[i%l]\n",
    "\n",
    "\n",
    "    # rejection sampling = naive m.c.           \n",
    "    #             while(S(X_tilde)<=L[k]):\n",
    "    #                 X_tilde = np.random.normal(0,1,1)\n",
    "\n",
    "\n",
    "    #            X_new = np.append(X_new, X_tilde)         \n",
    "\n",
    "        L = np.append(L, L_empirical(X, p_0, N))\n",
    "        k += 1\n",
    "\n",
    "    #print \"final k = \",k\n",
    "\n",
    "    N_L = np.sum((S(X)>q_test))\n",
    "    p_hat = N_L/float(N)*p_0**(k-1)\n",
    "    L_adapted = L[0:-1]\n",
    "    L_adapted = np.append(L_adapted, q_test)\n",
    "    \n",
    "    return p_hat, np.sqrt(N) * (p-p_hat)/p\n",
    "\n",
    "#     print \"real value of p:\" ,p\n",
    "#     print \"estimation of p: \", p_hat\n",
    "#     print \"relative variation: \",np.abs((p - p_hat))/p*np.sqrt(N)\n",
    "#     print \"N: \",N\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_sim = 100\n",
    "# #N = 100, 1000, 10000, 100000\n",
    "# sim_N =[[] for i in range(4)]\n",
    "# for n in range(4):\n",
    "#     for i in range(n_sim):\n",
    "#         sim_N[n] = fixed_sim(N = 10*10**n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from numba import autojit, prange\n",
    "n_sim = 1000\n",
    "sim_5000 = [[] for i in range(n_sim)]\n",
    "#@autojit\n",
    "def parallel_sim():\n",
    "    for i in range(n_sim):\n",
    "        sim_5000[i] = adapted_sim(1000,3)\n",
    "parallel_sim ()    \n",
    "sim_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = [15,5])\n",
    "plt.hist(np.array(sim_5000)[:,1],bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
